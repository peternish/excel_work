{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "import tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nimport numpy as np\nimport h5py\nfrom sklearn.model_selection import train_test_split\nfrom os import walk"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Acquire The Data"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "batch_size = 128\nimg_rows, img_cols = 28, 28       # image dims"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "#load npy arrays \n"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['broom.npy', 'aircraft_carrier.npy', 'alarm_clock.npy', 'ant.npy', 'cell_phone.npy', 'baseball.npy', 'asparagus.npy', 'dolphin.npy', 'crocodile.npy', 'bee.npy']\n"]}], "source": "data_path = \"data_files/\" # folder for image files\nfor (dirpath, dirnames, filenames) in walk(data_path):\n    pass # file names accumulate in list  'filenames'\nprint(filenames)"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["100000\n"]}], "source": "num_images = 1000000 ### was 100000, reduce this number if memory issues.\nnum_files = len(filenames) # *** we have 10 files ***\nimages_per_category = num_images//num_files\nseed = np.random.randint(1, 10e7)\ni=0\nprint(images_per_category)"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "for file in filenames:\n    file_path = data_path + file\n    x = np.load(file_path)\n    x = x.astype('float32')    ##normalise images\n    x /= 255.0\n    y = [i] * len(x) # create numeric label for this image\n\n    x = x[:images_per_category] # get our sample of images\n    y = y[:images_per_category] # get our sample of labels\n\n    if i == 0:\n        x_all = x\n        y_all = y\n    else:\n        x_all = np.concatenate((x,x_all), axis=0)\n        y_all = np.concatenate((y,y_all), axis=0)\n    i += 1"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": "#split data arrays into  train and test segments\nx_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=42)"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": "y_train = tf.keras.utils.to_categorical(y_train, num_files)\ny_test = tf.keras.utils.to_categorical(y_test, num_files)"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["x_train shape: (800000, 28, 28, 1)\n", "800000 train samples\n", "200000 test samples\n"]}], "source": "print('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create the model"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Compiling...........\n"]}], "source": "model = tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Flatten())\n\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.Dense(num_files, activation='softmax'))\nprint(\"Compiling...........\")"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n              optimizer=tf.keras.optimizers.Adadelta(),\n              metrics=['accuracy'])"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train the model"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Train on 720000 samples, validate on 80000 samples\n", "720000/720000 [==============================] - 89s 123us/sample - loss: 2.2132 - accuracy: 0.1930 - val_loss: 2.0671 - val_accuracy: 0.3997\n"]}, {"data": {"text/plain": ["<tensorflow.python.keras.callbacks.History at 0x7efc56963780>"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "epochs=1 # for testing, for training use 25\ncallbacks=[tf.keras.callbacks.TensorBoard(log_dir = \"./tb_log_dir\", histogram_freq = 0)]\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          callbacks=callbacks,\n          verbose=1,\n          validation_data=(x_valid, y_valid))"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["200000/200000 [==============================] - 10s 50us/sample - loss: 2.0684 - accuracy: 0.3971\n", "Test loss: 2.068418756465912\n", "Test accuracy: 0.39709\n"]}], "source": "score = model.evaluate(x_test, y_test, verbose=1)\n\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Test The Model "]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['broom', 'aircraft_carrier', 'alarm_clock', 'ant', 'cell_phone', 'baseball', 'asparagus', 'dolphin', 'crocodile', 'bee']\n", "\n", "For each pair in the following, the first label is predicted, second is actual\n", "\n", "-------------------------\n", "cell_phone\n", "alarm_clock\n", "-------------------------\n", "-------------------------\n", "baseball\n", "baseball\n", "-------------------------\n", "-------------------------\n", "asparagus\n", "broom\n", "-------------------------\n", "-------------------------\n", "bee\n", "cell_phone\n", "-------------------------\n", "-------------------------\n", "bee\n", "bee\n", "-------------------------\n", "-------------------------\n", "alarm_clock\n", "cell_phone\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "cell_phone\n", "-------------------------\n", "-------------------------\n", "asparagus\n", "broom\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "baseball\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "aircraft_carrier\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "cell_phone\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "crocodile\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "aircraft_carrier\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "ant\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "bee\n", "-------------------------\n", "-------------------------\n", "baseball\n", "baseball\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "baseball\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "ant\n", "-------------------------\n", "-------------------------\n", "alarm_clock\n", "dolphin\n", "-------------------------\n", "-------------------------\n", "bee\n", "dolphin\n", "-------------------------\n"]}], "source": "#_test\n\nimport os\nlabels = [os.path.splitext(file)[0] for file in filenames]\nprint(labels)\nprint(\"\\nFor each pair in the following, the first label is predicted, second is actual\\n\")\nfor i in range(20):\n    t = np.random.randint(len(x_test) )\n    x1= x_test[t]\n    x1 = x1.reshape(1,28,28,1)\n    p = model.predict(x1)\n    print(\"-------------------------\")\n    print(labels[np.argmax(p)])\n    print(labels[np.argmax(y_test[t])])\n    print(\"-------------------------\")\n\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Save, Reload and Retest the Model"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": "model.save(\"./QDrawModel.h5\")"}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": "del model"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": "from tensorflow.keras.models import load_model\n"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": "import numpy as np"}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model: \"sequential\"\n", "_________________________________________________________________\n", "Layer (type)                 Output Shape              Param #   \n", "=================================================================\n", "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n", "_________________________________________________________________\n", "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n", "_________________________________________________________________\n", "dropout (Dropout)            (None, 13, 13, 32)        0         \n", "_________________________________________________________________\n", "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n", "_________________________________________________________________\n", "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n", "_________________________________________________________________\n", "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n", "_________________________________________________________________\n", "flatten (Flatten)            (None, 1600)              0         \n", "_________________________________________________________________\n", "dense (Dense)                (None, 128)               204928    \n", "_________________________________________________________________\n", "dropout_2 (Dropout)          (None, 128)               0         \n", "_________________________________________________________________\n", "dense_1 (Dense)              (None, 10)                1290      \n", "=================================================================\n", "Total params: 225,034\n", "Trainable params: 225,034\n", "Non-trainable params: 0\n", "_________________________________________________________________\n"]}], "source": "model = load_model('./QDrawModel.h5')\nmodel.summary()"}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["For each pair, first is predicted, second is actual\n", "-------------------------\n", "broom\n", "broom\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "alarm_clock\n", "-------------------------\n", "-------------------------\n", "crocodile\n", "dolphin\n", "-------------------------\n", "-------------------------\n", "alarm_clock\n", "alarm_clock\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "aircraft_carrier\n", "-------------------------\n", "-------------------------\n", "bee\n", "crocodile\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "alarm_clock\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "cell_phone\n", "-------------------------\n", "-------------------------\n", "bee\n", "crocodile\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "asparagus\n", "-------------------------\n", "-------------------------\n", "broom\n", "broom\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "alarm_clock\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "crocodile\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "aircraft_carrier\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "dolphin\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "cell_phone\n", "-------------------------\n", "-------------------------\n", "broom\n", "broom\n", "-------------------------\n", "-------------------------\n", "bee\n", "ant\n", "-------------------------\n", "-------------------------\n", "aircraft_carrier\n", "dolphin\n", "-------------------------\n", "-------------------------\n", "cell_phone\n", "cell_phone\n", "-------------------------\n"]}], "source": "print(\"For each pair, first is predicted, second is actual\")\nfor i in range(20):\n    t = np.random.randint(len(x_test))\n    x1= x_test[t]\n    x1 = x1.reshape(1,28,28,1)\n    p = model.predict(x1)\n    print(\"-------------------------\")\n    print(labels[np.argmax(p)])\n    print(labels[np.argmax(y_test[t])])\n    print(\"-------------------------\")"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.7"}}, "nbformat": 4, "nbformat_minor": 2}